{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39dd0b31-3b96-4401-b396-82d8d5118ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "### initialize weights\n",
    "def xavier_initialization(input_size, output_size) ->np.ndarray:\n",
    "    bound = np.sqrt(6) / np.sqrt(input_size + output_size)\n",
    "    weights = np.random.uniform(-bound, bound, size=(input_size, output_size))\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7276cb1b-44a7-4a6c-b767-81a2c1cf1f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feed-Forward Layer\n",
    "class FeedForwardLayer():\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = xavier_initialization(input_size, output_size)\n",
    "        self.biases = np.zeros((1,output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        output = np.dot(self.x, self.weights) + self.biases\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def backward(self, d_values, learning_rate):\n",
    "        d_weights = np.dot(self.x.T, d_values)\n",
    "        d_biases = np.sum(d_values, axis=0, keepdims=True)\n",
    "\n",
    "\n",
    "        d_inputs = np.dot(d_values, self.weights.T)\n",
    "\n",
    "        self.weights -= learning_rate * d_weights\n",
    "        self.biases -= learning_rate * d_biases\n",
    "\n",
    "        return d_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "97ea0bc0-43cd-4579-b7b6-904987d00209",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding Nonlinearity\n",
    "class ReLuActivationFuction():\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        output = np.maximum(0, x)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def backward(self, d_values):\n",
    "        d_inputs = d_values * np.where(self.x>0, 1, 0)\n",
    "        \n",
    "        return d_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2dee673e-fa9e-41c7-a16a-d282c5b1a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loss Function Binary cross Entropy\n",
    "class BinaryCrossEntropy():\n",
    "    def forward(self, output, target):\n",
    "        loss = -(target * np.log(output) + (1 - target) * np.log(1 - output))\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    def backward(self, output, target):\n",
    "        return -target/output + (1 - target)/(1 - output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5123f65a-99c7-4561-9660-f2ad1eb0a63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For a binary classification problem, we can use sigmoid activation function to present probability\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class SigmoidActivationFunction():\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        output = sigmoid(x)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def backward(self, d_values):\n",
    "        return d_values * sigmoid(self.x) * (1 - sigmoid(self.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e5b581a2-f35c-4048-9660-091a6769ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Implementation\n",
    "\n",
    "class MLP_implementation():\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 output_size,\n",
    "                 hidden_layers,\n",
    "                 hidden_layers_size,\n",
    "                 hidden_activation_func,\n",
    "                 output_activation_function,\n",
    "                 loss_function,\n",
    "                ):\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.hidden_layers_size = hidden_layers_size\n",
    "        self.hidden_activation_func = hidden_activation_func\n",
    "        self.loss_function = loss_function\n",
    "        self.output_activation_function = output_activation_function\n",
    "        self.layers = []\n",
    "\n",
    "        ### Initialize hidden layers\n",
    "        for i in range(hidden_layers):\n",
    "            if i == 0:\n",
    "                layer = FeedForwardLayer(input_size, hidden_layers_size)\n",
    "            else:\n",
    "                layer = FeedForwardLayer(hidden_layers_size, hidden_layers_size)\n",
    "            self.layers.append(layer)\n",
    "        ### Initialize output layer\n",
    "        self.output_layer = FeedForwardLayer(hidden_layers_size, output_size)\n",
    "\n",
    "    def forward_pass(self, x):\n",
    "        output = x\n",
    "        for layer in self.layers:\n",
    "            output = layer.forward(output)\n",
    "            output = self.hidden_activation_func.forward(output)\n",
    "\n",
    "        output = self.output_layer.forward(output)\n",
    "        output = self.output_activation_function.forward(output)\n",
    "            \n",
    "        return output\n",
    "    def backward_pass(self, d_values, learning_rate):\n",
    "        #output layer\n",
    "        d_values = self.output_activation_function.backward(d_values)\n",
    "        d_values = self.output_layer.backward(d_values, learning_rate)\n",
    "\n",
    "        for layer in reversed(self.layers):\n",
    "            d_values = self.hidden_activation_func.backward(d_values)\n",
    "            d_values = layer.backward(d_values, learning_rate)\n",
    "    def train(self, input_data, targets, learning_rate=1, epochs=1):\n",
    "            for epoch in range(epochs):\n",
    "                random_order = np.random.permutation(np.array(range(len(input_data))))\n",
    "                for i in random_order:\n",
    "                    output = self.forward_pass(input_data[i].reshape((1, len(input_data[i])))) #forwardpass\n",
    "                    loss = self.loss_function.forward(output, targets[i]) #loss\n",
    "                    d_values = self.loss_function.backward(output, targets[i]) #backwardpass\n",
    "                    self.backward_pass(d_values, learning_rate)\n",
    "\n",
    "    def inference(self, input_data):\n",
    "        output= []\n",
    "        for i in range(len(input_data)):\n",
    "            output.append(self.forward_pass(input_data[i]))\n",
    "        return np.array(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6b32c9bd-b26d-49ec-bf15-8d1837253653",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize MLP\n",
    "xor_mlp = MLP_implementation(input_size=2,\n",
    "                            output_size=1,\n",
    "                            hidden_layers=3,\n",
    "                            hidden_layers_size=3,\n",
    "                            hidden_activation_func=ReLuActivationFuction(),\n",
    "                            output_activation_function=SigmoidActivationFunction(),\n",
    "                            loss_function=BinaryCrossEntropy(),\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "777430a7-edc7-4f1c-b29a-ba782fee6802",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training\n",
    "input_data = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "targets = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "xor_mlp.train(input_data, targets, learning_rate=0.05, epochs=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9e6f0354-3798-402d-90a4-096fcd683cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "### Evaluation\n",
    "def accuracy(predictions: np.ndarray, targets: np.ndarray, threshold=0.5) -> float:\n",
    "    binary_predictions = (predictions >= threshold).astype(int)\n",
    "    print(binary_predictions)\n",
    "    accuracy_value = np.mean(binary_predictions == targets)\n",
    "    return accuracy_value\n",
    "\n",
    "\n",
    "predictions = xor_mlp.inference(input_data).reshape(targets.shape)\n",
    "\n",
    "accuracy_value = accuracy(predictions, targets, threshold=0.5)\n",
    "print(accuracy_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a325894f-0bbb-4207-803b-f28d5074f260",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
